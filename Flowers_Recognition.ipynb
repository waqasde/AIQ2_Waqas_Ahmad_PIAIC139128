{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flowers_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXgJ6uT1NydQ"
      },
      "source": [
        "Assignment: Flowers Recognition <br>\n",
        "Dataset Description:<br>\n",
        "\n",
        "This dataset contains 4242 images of flowers.<br>\n",
        "The data collection is based on the data flicr, google images, yandex images.<br>\n",
        "You can use this datastet to recognize plants from the photo.<br>\n",
        "\n",
        "Attribute Information:<br>\n",
        "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>\n",
        "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>\n",
        "<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. </b> <br>\n",
        "This is a Multiclass Classification Problem.<br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7vy-ktuOKJH"
      },
      "source": [
        "WORKFLOW : <br>\n",
        "Load Data <br>\n",
        "Split into 60 and 40 ratio.<br>\n",
        "Encode labels.<br>\n",
        "Create Model<br>\n",
        "Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>\n",
        "Train the Model.<br>\n",
        "If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>\n",
        "Prediction should be > 85%<br>\n",
        "Evaluation Step<br>\n",
        "Prediction<br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri3Bg5qfPRic"
      },
      "source": [
        "Data : <br>\n",
        "https://drive.google.com/file/d/1-OX6wn5gA-bJpjPNfSyaYQLz-A-AB_uj/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xy3AC8tyjfi"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "from pathlib import Path\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Conv2D,Dense,Dropout,Input,Flatten,MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model,to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import image\n",
        "#Sir I did this specifically on local jupyter book that is why output which each step is not here all other were done in google colab\n",
        "# google lab was taking much much time in doing this due to big image folders\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOA8mk9Gy3oZ"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "p = Path('../input/flowers-recognition/flowers')\n",
        "dirs = p.glob('*')\n",
        "image_data = []\n",
        "labels = []\n",
        "label_dict = {'dandelion':0,'daisy':1,'flowers':2,'sunflower':3,'tulip':4,'rose':5}\n",
        "for folder_dir in dirs:\n",
        "    label= str(folder_dir).split('/')[-1]\n",
        "    cnt = 0\n",
        "    print(label)\n",
        "    for image_path in folder_dir.glob('*.jpg'):\n",
        "        img = image.load_img(image_path,target_size = (64,64))\n",
        "        img_array = image.img_to_array(img)\n",
        "        image_data.append(img_array)\n",
        "        labels.append(label_dict[label])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocid8xvfzEnA"
      },
      "source": [
        "print(len(image_data),len(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py8FICdXzLYH"
      },
      "source": [
        "x = np.array(image_data)\n",
        "y = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-uUzT5FzMS3"
      },
      "source": [
        "num_labels = len(np.unique(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOd8mlE6zR27"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFIVVXeLzZHo"
      },
      "source": [
        "image_size = x_train.shape[1]\n",
        "x_train = np.reshape(x_train,[-1,image_size,image_size,3])\n",
        "x_test = np.reshape(x_test,[-1,image_size,image_size,3])\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deC71HN_zgTO"
      },
      "source": [
        "y_train = to_categorical(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t4Baj0Gzj8X"
      },
      "source": [
        "input_shape = (64,64,3)\n",
        "inputs = Input(shape = input_shape)\n",
        "x = inputs\n",
        "x = Conv2D(32,kernel_size = 2,activation = 'relu',strides = 1,padding = 'same')(x)\n",
        "x = MaxPooling2D(pool_size = (2,2))(x)\n",
        "\n",
        "x = Conv2D(64,kernel_size = 2,activation = 'relu',strides = 1,padding = 'same')(x)\n",
        "x = MaxPooling2D(pool_size = (2,2))(x)\n",
        "\n",
        "\n",
        "x = Conv2D(128,kernel_size = 2,activation = 'relu',strides = 1,padding = 'same')(x)\n",
        "x = Conv2D(256,kernel_size = 2,activation = 'relu',strides = 1,padding = 'same')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Flatten()(x)\n",
        "outputs = Dense(6,activation = 'softmax')(x)\n",
        "flower_classifier = Model(inputs,outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtlmh5YxzwFW"
      },
      "source": [
        "flower_classifier.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRk1dfCpz2yv"
      },
      "source": [
        "flower_classifier.fit(x_train,y_train,batch_size = 128,epochs = 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w30sTyILz-QC"
      },
      "source": [
        "test_case = flower_classifier.predict(x_test)\n",
        "print (test_case)\n",
        "y_test_pred = np.argmax(test_case,axis = 1)\n",
        "print (y_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMUy42Iq0GuA"
      },
      "source": [
        "for i in range(50):\n",
        "    print(\"actual\",y_test[i],\"predicted\",y_test_pred[i])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}