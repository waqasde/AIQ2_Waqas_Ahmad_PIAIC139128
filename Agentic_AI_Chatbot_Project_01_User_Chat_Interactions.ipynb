{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+IEjPYsyqx5ZydUPY9noo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waqasde/AIQ2_Waqas_Ahmad_PIAIC139128/blob/main/Agentic_AI_Chatbot_Project_01_User_Chat_Interactions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langsmith langchain_anthropic"
      ],
      "metadata": {
        "id": "XzflTqYfC5ye"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "705d4020-6ee8-44cc-b1a5-8c34e7172fc7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"Agentic AI Chatbot Prototype 1\"\n",
        "\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langsmith langchain_google_genai"
      ],
      "metadata": {
        "id": "Ua2VE6xkT2dc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    api_key=gemini_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "_V9OAvp8TpBe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7451151f-41fc-4af0-9359-024ae51b7225"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U tavily-python langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0c52923c-5665-4f8c-a1ba-9799e369c49e"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated, Literal\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import AIMessage, ToolMessage, SystemMessage\n",
        "from pydantic import BaseModel\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    ask_human: bool\n",
        "    ask_user: bool\n",
        "    long_term_memory: dict  # To personalize answers based on prior interactions\n",
        "\n",
        "class RequestAssistance(BaseModel):\n",
        "    \"\"\"Escalate the conversation to an expert.\"\"\"\n",
        "    request: str\n",
        "\n",
        "# Define the system message to enforce healthcare context\n",
        "system_prompt = SystemMessage(\n",
        "    content=(\n",
        "        \"You are a healthcare assistant chatbot. Only answer questions related to healthcare topics, such as \"\n",
        "        \"medicine, diseases, symptoms, treatments, therapies, diagnoses, hospitals, or doctors. \"\n",
        "        \"If a query is unrelated to healthcare, politely respond that you can only assist with healthcare-related queries.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Initialize tools\n",
        "tool = TavilySearchResults(max_results=5)\n",
        "tools = [tool]\n",
        "\n",
        "# Initialize LLM with tools and personalization\n",
        "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])\n",
        "\n",
        "def chatbot(state: State):\n",
        "    # Inject the system prompt if it's not already included\n",
        "    if not any(isinstance(msg, SystemMessage) for msg in state[\"messages\"]):\n",
        "        state[\"messages\"].insert(0, system_prompt)\n",
        "\n",
        "    user_message = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
        "\n",
        "    # Check for personalization\n",
        "    if \"user_name\" in state[\"long_term_memory\"]:\n",
        "        personalized_greeting = f\"Hello, {state['long_term_memory']['user_name']}! \"\n",
        "        user_message = personalized_greeting + user_message\n",
        "\n",
        "    # Pause and ask the user for more information if needed\n",
        "    if \"?\" in user_message and len(user_message.split()) < 5:\n",
        "        state[\"ask_user\"] = True\n",
        "        return {\n",
        "            \"messages\": [\n",
        "                AIMessage(content=\"Could you please provide more details about your question?\")\n",
        "            ],\n",
        "            \"ask_user\": True,\n",
        "        }\n",
        "\n",
        "    # Escalate to a human assistant if the chatbot is unsure\n",
        "    if \"I don't know\" in user_message or \"uncertain\" in user_message:\n",
        "        state[\"ask_human\"] = True\n",
        "        return {\n",
        "            \"messages\": [\n",
        "                AIMessage(content=\"I'm unsure about this. Let me connect you to a human assistant for further help.\")\n",
        "            ],\n",
        "            \"ask_human\": True,\n",
        "        }\n",
        "\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    ask_human = False\n",
        "    if (\n",
        "        response.tool_calls\n",
        "        and response.tool_calls[0][\"name\"] == RequestAssistance.__name__\n",
        "    ):\n",
        "        ask_human = True\n",
        "\n",
        "    # Save to long-term memory if personal information is shared\n",
        "    if \"my name is\" in user_message.lower():\n",
        "        name = user_message.split(\"my name is\")[-1].strip()\n",
        "        state[\"long_term_memory\"][\"user_name\"] = name\n",
        "\n",
        "    return {\"messages\": [response], \"ask_human\": ask_human, \"ask_user\": False}\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_node(\"tools\", ToolNode(tools=[tool]))\n",
        "\n",
        "def create_response(response: str, ai_message: AIMessage):\n",
        "    return ToolMessage(\n",
        "        content=response,\n",
        "        tool_call_id=ai_message.tool_calls[0][\"id\"],\n",
        "    )\n",
        "\n",
        "def human_node(state: State):\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            AIMessage(content=\"A human assistant has been notified and will assist you shortly.\")\n",
        "        ],\n",
        "        \"ask_human\": False,\n",
        "    }\n",
        "\n",
        "def user_interaction_node(state: State):\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            AIMessage(content=\"Thanks for the clarification. Let me continue assisting you.\"),\n",
        "        ],\n",
        "        \"ask_user\": False,\n",
        "    }\n",
        "\n",
        "graph_builder.add_node(\"human\", human_node)\n",
        "graph_builder.add_node(\"user_interaction\", user_interaction_node)\n",
        "\n",
        "def select_next_node(state: State):\n",
        "    if state[\"ask_human\"]:\n",
        "        return \"human\"\n",
        "    if state[\"ask_user\"]:\n",
        "        return \"user_interaction\"\n",
        "    return tools_condition(state)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    select_next_node,\n",
        "    {\"human\": \"human\", \"user_interaction\": \"user_interaction\", \"tools\": \"tools\", END: END},\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(\"human\", \"chatbot\")\n",
        "graph_builder.add_edge(\"user_interaction\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(\n",
        "    checkpointer=memory,\n",
        "    interrupt_before=[\"human\", \"user_interaction\"],\n",
        ")\n"
      ],
      "metadata": {
        "id": "UPaySC9SR4lS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ePsjvHfwSPkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "\n",
        "# Function to stream graph updates\n",
        "def stream_graph_updates(user_input: str):\n",
        "    \"\"\"\n",
        "    Streams updates from the chatbot graph based on user input.\n",
        "\n",
        "    Args:\n",
        "        user_input (str): The input provided by the user.\n",
        "    \"\"\"\n",
        "    # Initialize state with default values\n",
        "    state = {\n",
        "        \"messages\": [(\"user\", user_input)],\n",
        "        \"ask_human\": False,\n",
        "        \"ask_user\": False,\n",
        "        \"long_term_memory\": {},  # Initialize long-term memory\n",
        "    }\n",
        "\n",
        "    # Configuration for graph streaming\n",
        "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "    # Validate user input before processing\n",
        "    if not user_input.strip():\n",
        "        print(\"Assistant: It seems you didn't enter anything. Please ask a healthcare-related question.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Stream responses from the graph\n",
        "        for event in graph.stream(state, config):\n",
        "            for value in event.values():\n",
        "                print(\"Assistant:\", value[\"messages\"][-1].content)\n",
        "    except KeyError as e:\n",
        "        print(f\"KeyError: {e} - Ensure all required keys are initialized in the state.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the interactive healthcare chatbot.\n",
        "    \"\"\"\n",
        "    print(\"Welcome to the Healthcare Chatbot! Ask me simple health-related questions.\")\n",
        "    print(\"Type 'quit', 'exit', or 'q' to end the conversation.\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Get user input\n",
        "            user_input = input(\"You: \").strip()\n",
        "\n",
        "            # Exit condition\n",
        "            if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "                print(\"Goodbye! Take care of your health.\")\n",
        "                break\n",
        "\n",
        "            # Stream graph updates with user input\n",
        "            stream_graph_updates(user_input)\n",
        "        except KeyboardInterrupt:\n",
        "            # Graceful exit on Ctrl+C\n",
        "            print(\"\\nGoodbye! Take care of your health.\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            # Handle unexpected errors\n",
        "            print(f\"An unexpected error occurred: {e}\")\n",
        "            break\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6-kZJEbSaO-",
        "outputId": "7eeaae23-6309-43b5-c301-a3d7f975509c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Healthcare Chatbot! Ask me simple health-related questions.\n",
            "Type 'quit', 'exit', or 'q' to end the conversation.\n",
            "You: diabetes\n",
            "Assistant: Diabetes is a chronic metabolic disorder characterized by elevated levels of blood sugar (glucose).  There are several types, including type 1, type 2, and gestational diabetes.  Each has different causes and management strategies.  To provide you with more specific information, could you tell me what you'd like to know about diabetes?  For example, are you interested in the symptoms, causes, treatments, or management of a particular type of diabetes?\n",
            "\n",
            "You: what is treatments\n",
            "Assistant: Diabetes treatments vary depending on the type of diabetes and the individual's specific needs.  There's no single \"cure,\" but treatments aim to manage blood sugar levels and prevent complications.\n",
            "\n",
            "**Type 1 Diabetes:** This type requires lifelong insulin therapy, typically through injections or an insulin pump.  Careful monitoring of blood sugar levels is also crucial.\n",
            "\n",
            "**Type 2 Diabetes:** Treatment often begins with lifestyle changes such as diet and exercise.  If these aren't enough to control blood sugar, medication may be added.  Oral medications, such as metformin, or injectable medications like GLP-1 receptor agonists or SGLT2 inhibitors, might be prescribed.  In some cases, insulin therapy may eventually be necessary.\n",
            "\n",
            "**Gestational Diabetes:** Treatment focuses on managing blood sugar levels through diet and exercise.  Some women may require insulin injections.  After delivery, blood sugar levels usually return to normal.\n",
            "\n",
            "\n",
            "This information is for general knowledge only and is not a substitute for professional medical advice.  It's essential to consult with a doctor or other qualified healthcare professional for diagnosis and treatment of diabetes or any other medical condition.  They can assess your individual situation and recommend the most appropriate treatment plan.\n",
            "\n",
            "You: i am taking 8 glass of water daily is it right?\n",
            "Assistant: The recommendation of eight glasses of water a day is a guideline, not a strict rule.  The amount of water you need depends on several factors, including your activity level, climate, overall health, and diet.  While eight glasses is a good starting point for many, some people may need more or less.  If you're concerned about your hydration, it's best to consult a doctor or other healthcare professional. They can assess your individual needs and advise you on the appropriate amount of water intake.  Also, pay attention to the color of your urine; pale yellow is a good indicator of adequate hydration.\n",
            "\n",
            "You: i am getting 135 sugar level in morning is it diabetic?\n",
            "Assistant: A single blood sugar reading of 135 mg/dL in the morning doesn't definitively diagnose diabetes.  To determine if you have diabetes, a healthcare professional needs to perform a comprehensive assessment, which may include several blood sugar tests over time, such as a fasting blood glucose test or an HbA1c test.  These tests provide a more accurate picture of your average blood sugar levels.  A single reading can be affected by many factors, including recent food intake, stress, and illness.  It's crucial to consult a doctor or other qualified healthcare provider to discuss your blood sugar level and undergo proper testing for an accurate diagnosis.\n",
            "\n",
            "You: q\n",
            "Goodbye! Take care of your health.\n"
          ]
        }
      ]
    }
  ]
}